{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook analyzes data from https://github.com/HuthLab/deep-fMRI-dataset. To set up, see instructions in the `deep-fMRI-dataset` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import datasets\n",
    "import numpy as np\n",
    "from os.path import join\n",
    "# from ridge_utils.SemanticModel import SemanticModel\n",
    "from matplotlib import pyplot as plt\n",
    "from typing import List\n",
    "from sklearn.linear_model import RidgeCV, LogisticRegressionCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# from feature_spaces import em_data_dir, data_dir, results_dir\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "# from fit_linear_models import get_dsets\n",
    "# from ridge_utils.SemanticModel import SemanticModel\n",
    "# import encoding_utils, feature_spaces\n",
    "from transformers.pipelines.pt_utils import KeyDataset\n",
    "# from feature_spaces import *\n",
    "from transformers import pipeline\n",
    "import datasets\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import data\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emotion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset emotion (/home/chansingh/.cache/huggingface/datasets/emotion/default/0.0.0/348f63ca8e27b3713b6c04d723efe6d824a56fb3d1449794716c0f0296072705)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed61389785aa4b01b8ad7dd86d7292e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset emotion (/home/chansingh/.cache/huggingface/datasets/emotion/default/0.0.0/348f63ca8e27b3713b6c04d723efe6d824a56fb3d1449794716c0f0296072705)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c8b6dd95b1b455c8041dc5c2f129754",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 1/15 [00:01<00:15,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rotten_tomatoes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset rotten_tomatoes (/home/chansingh/.cache/huggingface/datasets/rotten_tomatoes/default/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "012505a1748341b299704781638eebcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset rotten_tomatoes (/home/chansingh/.cache/huggingface/datasets/rotten_tomatoes/default/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35a9b95ce1de4a11ab4d941a08216e4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 2/15 [00:02<00:14,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweet_eval\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset tweet_eval (/home/chansingh/.cache/huggingface/datasets/tweet_eval/hate/1.1.0/12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed230ceda6134cba9ac4e5c7288c0f1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset tweet_eval (/home/chansingh/.cache/huggingface/datasets/tweet_eval/hate/1.1.0/12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5bd364a7aae4159b2ad499599cafa8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 3/15 [00:03<00:13,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sst2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset sst2 (/home/chansingh/.cache/huggingface/datasets/sst2/default/2.0.0/9896208a8d85db057ac50c72282bcb8fe755accc671a57dd8059d4e130961ed5)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "475a36f47a6246bc9fdb0ea5f59f3af9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "r = defaultdict(list)\n",
    "for dset in tqdm([\n",
    "    # 'trec',\n",
    "    'emotion', 'rotten_tomatoes', 'tweet_eval', 'sst2',\n",
    "    # 'go_emotions', 'poem_sentiment', \n",
    "    # 'ethics-commonsense', 'ethics-deontology', 'ethics-justice', 'ethics-utilitarianism', 'ethics-virtue',\n",
    "    'probing-subj_number', 'probing-word_content', 'probing-obj_number',\n",
    "    'probing-past_present', 'probing-sentence_length', 'probing-top_constituents',\n",
    "    'probing-tree_depth', 'probing-coordination_inversion', 'probing-odd_man_out',\n",
    "    'probing-bigram_shift', 'moral_stories',\n",
    "]):\n",
    "    print(dset)\n",
    "    X, y, X_test, y_test = data.get_dsets(dataset=dset, seed=1)\n",
    "    values, counts = np.unique(y, return_counts=True)\n",
    "    y_majority_frac_train = counts.max() / len(y)\n",
    "    n_classes = values.size\n",
    "    values, counts = np.unique(y_test, return_counts=True)\n",
    "    y_majority_frac_test = counts.max() / len(y)\n",
    "    lens_train = [len(x) for x in X]\n",
    "\n",
    "    r['dset'].append(dset)\n",
    "    r['n_train'].append(len(X))\n",
    "    r['n_test'].append(len(X_test))\n",
    "    r['y_majority_frac_train'].append(y_majority_frac_train)\n",
    "    r['y_majority_frac_test'].append(y_majority_frac_test)\n",
    "    r['len_avg_train'].append(np.mean(lens_train))\n",
    "    r['len_std_train'].append(np.std(lens_train))\n",
    "    r['n_classes'].append(n_classes)\n",
    "    r['ex1'].append(X[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(r)\n",
    "df.to_pickle('../processed/data_table.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dset</th>\n",
       "      <th>n_train</th>\n",
       "      <th>n_test</th>\n",
       "      <th>y_majority_frac_train</th>\n",
       "      <th>y_majority_frac_test</th>\n",
       "      <th>len_avg_train</th>\n",
       "      <th>len_std_train</th>\n",
       "      <th>n_classes</th>\n",
       "      <th>ex1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>emotion</td>\n",
       "      <td>16000</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.34</td>\n",
       "      <td>96.85</td>\n",
       "      <td>55.90</td>\n",
       "      <td>6</td>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rotten_tomatoes</td>\n",
       "      <td>8530</td>\n",
       "      <td>1066</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>113.97</td>\n",
       "      <td>51.05</td>\n",
       "      <td>2</td>\n",
       "      <td>the rock is destined to be the 21st century's ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tweet_eval</td>\n",
       "      <td>9000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.58</td>\n",
       "      <td>122.84</td>\n",
       "      <td>67.20</td>\n",
       "      <td>2</td>\n",
       "      <td>@user nice new signage. Are you not concerned ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sst2</td>\n",
       "      <td>67349</td>\n",
       "      <td>872</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.56</td>\n",
       "      <td>53.51</td>\n",
       "      <td>43.41</td>\n",
       "      <td>2</td>\n",
       "      <td>hide new secretions from the parental units</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>probing-subj_number</td>\n",
       "      <td>82010</td>\n",
       "      <td>8088</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>84.63</td>\n",
       "      <td>114.20</td>\n",
       "      <td>2</td>\n",
       "      <td>Coming from a xenophobic race that possesses t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>probing-word_content</td>\n",
       "      <td>83868</td>\n",
       "      <td>8357</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>83.86</td>\n",
       "      <td>95.66</td>\n",
       "      <td>1000</td>\n",
       "      <td>It just hadn 't seemed important, and he didn ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>probing-obj_number</td>\n",
       "      <td>80124</td>\n",
       "      <td>8014</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>83.40</td>\n",
       "      <td>101.86</td>\n",
       "      <td>2</td>\n",
       "      <td>Money would replace the drugs in the bags, onc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>probing-past_present</td>\n",
       "      <td>85700</td>\n",
       "      <td>8552</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>71.20</td>\n",
       "      <td>75.14</td>\n",
       "      <td>2</td>\n",
       "      <td>She shone her light around the space, followin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>probing-sentence_length</td>\n",
       "      <td>87408</td>\n",
       "      <td>8653</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>87.04</td>\n",
       "      <td>165.93</td>\n",
       "      <td>6</td>\n",
       "      <td>But it was not here.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>probing-top_constituents</td>\n",
       "      <td>70185</td>\n",
       "      <td>7451</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>88.59</td>\n",
       "      <td>508.29</td>\n",
       "      <td>20</td>\n",
       "      <td>I wanted to start asking questions now, but fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>probing-tree_depth</td>\n",
       "      <td>85340</td>\n",
       "      <td>8675</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.18</td>\n",
       "      <td>70.75</td>\n",
       "      <td>65.54</td>\n",
       "      <td>7</td>\n",
       "      <td>Who knew who would be there?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>probing-coordination_inversion</td>\n",
       "      <td>100002</td>\n",
       "      <td>10002</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>77.43</td>\n",
       "      <td>25.39</td>\n",
       "      <td>2</td>\n",
       "      <td>She was a regular at the Friday charity sessio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>probing-odd_man_out</td>\n",
       "      <td>83157</td>\n",
       "      <td>8402</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>93.98</td>\n",
       "      <td>105.46</td>\n",
       "      <td>2</td>\n",
       "      <td>Gideon brought his phone to his ear and resona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>probing-bigram_shift</td>\n",
       "      <td>100000</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>63.40</td>\n",
       "      <td>30.39</td>\n",
       "      <td>2</td>\n",
       "      <td>A week she'd been with the man, just a week, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>moral_stories</td>\n",
       "      <td>20000</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>126.58</td>\n",
       "      <td>25.40</td>\n",
       "      <td>2</td>\n",
       "      <td>It's good to do activities together with your ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              dset  n_train  n_test  y_majority_frac_train  \\\n",
       "0                          emotion    16000    2000                   0.34   \n",
       "1                  rotten_tomatoes     8530    1066                   0.50   \n",
       "2                       tweet_eval     9000    1000                   0.58   \n",
       "3                             sst2    67349     872                   0.56   \n",
       "4              probing-subj_number    82010    8088                   0.50   \n",
       "5             probing-word_content    83868    8357                   0.00   \n",
       "6               probing-obj_number    80124    8014                   0.50   \n",
       "7             probing-past_present    85700    8552                   0.50   \n",
       "8          probing-sentence_length    87408    8653                   0.17   \n",
       "9         probing-top_constituents    70185    7451                   0.05   \n",
       "10              probing-tree_depth    85340    8675                   0.18   \n",
       "11  probing-coordination_inversion   100002   10002                   0.50   \n",
       "12             probing-odd_man_out    83157    8402                   0.50   \n",
       "13            probing-bigram_shift   100000   10000                   0.50   \n",
       "14                   moral_stories    20000    2000                   0.50   \n",
       "\n",
       "    y_majority_frac_test  len_avg_train  len_std_train  n_classes  \\\n",
       "0                   0.34          96.85          55.90          6   \n",
       "1                   0.50         113.97          51.05          2   \n",
       "2                   0.58         122.84          67.20          2   \n",
       "3                   0.56          53.51          43.41          2   \n",
       "4                   0.50          84.63         114.20          2   \n",
       "5                   0.00          83.86          95.66       1000   \n",
       "6                   0.50          83.40         101.86          2   \n",
       "7                   0.50          71.20          75.14          2   \n",
       "8                   0.17          87.04         165.93          6   \n",
       "9                   0.05          88.59         508.29         20   \n",
       "10                  0.18          70.75          65.54          7   \n",
       "11                  0.50          77.43          25.39          2   \n",
       "12                  0.50          93.98         105.46          2   \n",
       "13                  0.50          63.40          30.39          2   \n",
       "14                  0.50         126.58          25.40          2   \n",
       "\n",
       "                                                  ex1  \n",
       "0                             i didnt feel humiliated  \n",
       "1   the rock is destined to be the 21st century's ...  \n",
       "2   @user nice new signage. Are you not concerned ...  \n",
       "3        hide new secretions from the parental units   \n",
       "4   Coming from a xenophobic race that possesses t...  \n",
       "5   It just hadn 't seemed important, and he didn ...  \n",
       "6   Money would replace the drugs in the bags, onc...  \n",
       "7   She shone her light around the space, followin...  \n",
       "8                                But it was not here.  \n",
       "9   I wanted to start asking questions now, but fo...  \n",
       "10                       Who knew who would be there?  \n",
       "11  She was a regular at the Friday charity sessio...  \n",
       "12  Gideon brought his phone to his ear and resona...  \n",
       "13  A week she'd been with the man, just a week, a...  \n",
       "14  It's good to do activities together with your ...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle('../processed/data_table.pkl')\n",
    "df.round(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.embgam')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "559535f78d940c882783b39501b2581b5193373045707e5f8a51d046029cfd38"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
