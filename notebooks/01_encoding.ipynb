{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "sys.path.append('../experiments')\n",
    "import dvu\n",
    "import seaborn as sns\n",
    "import os\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "from matplotlib import pyplot as plt\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "import imodelsx.process_results\n",
    "import neuro1.features.qa_questions as qa_questions\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "import analyze_helper\n",
    "import viz\n",
    "fit_encoding = __import__('02_fit_encoding')\n",
    "dvu.set_style()\n",
    "\n",
    "# results_dir = analyze_helper.best_results_dir\n",
    "# r, cols_varied, mets = analyze_helper.load_clean_results(results_dir)\n",
    "# joblib.dump((r, cols_varied, mets), '../results/results_aggregated.pkl')\n",
    "# (r, cols_varied, mets) = joblib.load('../results/results_aggregated.pkl')\n",
    "\n",
    "# metric_sort = 'corrs_tune_pc_mean'\n",
    "# r = analyze_helper.add_corrs_tune_pc_weighted(r)\n",
    "# metric_sort = 'corrs_tune_pc_weighted_mean'\n",
    "# if not metric_sort in mets:\n",
    "    # mets.append(metric_sort)\n",
    "\n",
    "# r_mini = r.drop(columns=['corrs_tune_pc', 'corrs_test_pc', 'corrs_test'])\n",
    "# joblib.dump((r_mini, cols_varied, mets), '../results/results_aggregated_mini.pkl')\n",
    "(r, cols_varied, mets) = joblib.load('../results/results_aggregated_mini.pkl')\n",
    "r = r[r.feature_selection_alpha_index < 0]\n",
    "r = r[r.distill_model_path.isna()]\n",
    "r = r[~(r.feature_space == 'qa_embedder-25')]\n",
    "r = r[r.pc_components == 100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### best results breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r['feature_space_simplified'] = r['feature_space'].apply(\n",
    "    lambda x: 'llama' if 'llama' in x else x\n",
    ")\n",
    "d = r\n",
    "# d = d[~((d.feature_space == 'qa_embedder-10') & (d.ndelays != 8))]\n",
    "d = d[~((d.feature_space == 'qa_embedder-10') &\n",
    "        (d.qa_embedding_model != 'ensemble1'))]\n",
    "d = d[~((d.feature_space.str.contains('llama')) & (d.ndelays != 4))]\n",
    "d = d[d.pc_components == 100]\n",
    "\n",
    "d = d.sort_values(\n",
    "    by=metric_sort, ascending=False)\n",
    "d = d.groupby(['subject', 'feature_space_simplified'])[mets]\n",
    "d = d.first().reset_index()\n",
    "# display(d)\n",
    "tab = d.pivot_table(index='subject', columns='feature_space_simplified',\n",
    "                    values='corrs_test_mean', aggfunc='mean')\n",
    "# d.pivot_table(index='subject', columns='feature_space_simplified',\n",
    "#                     values='corrs_test_mean_sem', aggfunc='mean')\n",
    "\n",
    "# # add average row\n",
    "tab.loc['AVG'] = tab.mean()\n",
    "display(tab.round(3))\n",
    "\n",
    "tab['Subject'] = tab.index.str.replace('UT', '')\n",
    "# rename stuf\n",
    "tab.columns = tab.columns.map(lambda x: {\n",
    "    'bert-10': 'BERT',\n",
    "    'eng1000': 'Eng1000',\n",
    "    'llama': 'LLaMA',\n",
    "    'qa_embedder-10': 'QA-Emb',\n",
    "    'finetune_roberta-base-10': 'QA-Emb (distill logits)',\n",
    "    'finetune_roberta-base_binary-10': 'QA-Emb (distill)',\n",
    "}.get(x, x))\n",
    "\n",
    "plot_data = tab.melt(id_vars='Subject',\n",
    "                     var_name='feature_space_simplified', value_name='corrs_test_mean')\n",
    "# fig, ax = plt.subplots(figsize=(4, 3))\n",
    "plt.figure(figsize=(4.5, 3.2))\n",
    "sns.barplot(\n",
    "    plot_data, x='Subject', y='corrs_test_mean',\n",
    "    hue='feature_space_simplified',\n",
    "    hue_order=[\n",
    "        'Eng1000', 'QA-Emb', 'BERT', 'LLaMA'],\n",
    "    palette=['mediumseagreen', 'C0', '#777', '#333'])  # blues: '#52aae7', 'C0', '#004481'\n",
    "# move legend outside\n",
    "plt.legend(loc='upper left', frameon=False)  # , bbox_to_anchor=(0.75, 1.2))\n",
    "plt.ylabel('Test correlation')\n",
    "plt.ylim((0.05, 0.15))\n",
    "plt.tight_layout()\n",
    "plt.savefig('../figs/corr_best.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tab.round(3)[['QA-Emb', 'QA-Emb (distill)',\n",
    "                  'QA-Emb (distill logits)', 'Eng1000']].astype(str)\n",
    "# bold the bottom row\n",
    "t.loc['AVG'] = t.loc['AVG'].apply(lambda x: f'\\\\textbf{{{x}}}')\n",
    "# bold AVG index label\n",
    "t = t.rename(index={'AVG': '\\\\textbf{AVG}'})\n",
    "# delete the column label name\n",
    "t.columns.name = None\n",
    "t.index.name = None\n",
    "\n",
    "# export to latex using booktabs\n",
    "print(t.to_latex(escape=False, column_format='lrrrr', float_format='%.3f'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### qa version breakdowns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = r[(r.feature_space == 'qa_embedder-10') * (r.pc_components == 100)]\n",
    "# d = r[(r.pc_components == 100)]\n",
    "d = d[d.ndelays == 8]\n",
    "d = d[~d.qa_embedding_model.str.contains('mixt')]\n",
    "d['qa_questions_version'] = d['qa_questions_version'].apply(\n",
    "    viz.version_rename)\n",
    "cols = ['subject', 'qa_questions_version', 'qa_embedding_model']\n",
    "d = d.groupby(cols)[mets].mean()\n",
    "d = (\n",
    "    d.pivot_table(index=[c for c in cols if not c == 'qa_embedding_model'],\n",
    "                  columns='qa_embedding_model', values='corrs_test_mean', aggfunc='mean')\n",
    ")\n",
    "# add average row to multiindex\n",
    "for qa_questions_version in sorted(d.index.get_level_values('qa_questions_version').unique()):\n",
    "    dn = d.loc[(slice(None), qa_questions_version), :]\n",
    "    d.loc[('AVG', qa_questions_version), :] = dn.mean()\n",
    "display(\n",
    "    d\n",
    "    .style.background_gradient(cmap='magma')  # , axis=0)\n",
    "    .format(precision=3)\n",
    ")\n",
    "\n",
    "d = d.drop(columns='llama3-8B-refined')\n",
    "d.columns.name = None\n",
    "d.index.names = ['Subject', 'Questions']\n",
    "d.columns = d.columns.map(viz.feature_space_rename)\n",
    "d = d.loc[(slice(None), ['Prompts 1-3 (376 questions)',\n",
    "           'Prompts 1-5 (518 questions)', 'Prompts 1-6 (674 questions)']), :]\n",
    "print(d.to_latex(escape=False, float_format='%.3f').replace(\n",
    "    '\\cline{1-5}', '\\midrule'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = r[(~r.feature_space.str.contains('qa_embedder')) * (r.pc_components == 100)]\n",
    "d = d[(~d.feature_space.str.contains('roberta'))]\n",
    "# d = r[(r.pc_components == 100)]\n",
    "# d = d[d.ndelays == 8]\n",
    "cols = ['subject', 'ndelays', 'feature_space']\n",
    "d = d.groupby(cols)[mets].mean()\n",
    "d = (\n",
    "    d.pivot_table(index=[c for c in cols if not c == 'feature_space'],\n",
    "                  columns='feature_space', values='corrs_test_mean', aggfunc='mean')\n",
    "    .rename(columns=viz.feature_space_rename)\n",
    "    # sort columns alphabetically\n",
    "    .sort_index(axis=1)\n",
    ")\n",
    "# add average row to multiindex\n",
    "for ndelays in sorted(d.index.get_level_values('ndelays').unique()):\n",
    "    dn = d.loc[(slice(None), ndelays), :]\n",
    "    d.loc[('AVG', ndelays), :] = dn.mean()\n",
    "\n",
    "\n",
    "d.columns.name = None\n",
    "d.index.names = ['Subject', 'Delays']\n",
    "display(d\n",
    "        .style.background_gradient(cmap='magma')  # , axis=0)\n",
    "        .format(precision=3)\n",
    "        )\n",
    "print(d.T.to_latex(escape=False, float_format='%.3f'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### look at all results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = r\n",
    "# d = d[d.feature_space == 'eng1000']\n",
    "# d = d[d.subject == 'UTS01']\n",
    "# d = d[~(d.feature_space == 'qa_embedder-10') | (d.ndelays == 8)]\n",
    "# d = d[d.feature_space == 'llama']\n",
    "cols_varied = [c for c in cols_varied if not c in [\n",
    "    'distill_model_path', 'feature_selection_alpha_index']]\n",
    "# d = d[(d.qa_questions_version == 'v1') *\n",
    "#   (d.qa_embedding_model == 'mistral 7B')]\n",
    "if len(cols_varied) > 0:\n",
    "    d = d.groupby(cols_varied)[mets].mean()\n",
    "else:\n",
    "    d = d[mets]\n",
    "\n",
    "(\n",
    "    d\n",
    "    # .sort_values(by='corrs_test_mean', ascending=False)\n",
    "    # .sort_values(by=metric_sort, ascending=False)\n",
    "    .rename(columns=lambda x: x.replace('_', ' ').replace('corrs', ''))\n",
    "    .style\n",
    "    .background_gradient(cmap='magma', axis=0)\n",
    "    .format(precision=3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # look at distill_model_path\n",
    "# d = r[(r.feature_space == 'qa_embedder-10') * (r.pc_components == 100)]\n",
    "# d = d.groupby(cols_varied)[mets].mean()\n",
    "# d.pivot_table(index=[c for c in cols_varied if not c == 'distill_model_path'],\n",
    "#               columns='distill_model_path', values='corrs_test_mean', aggfunc='mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare performance of a few different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qa = r[(r.feature_space == 'qa_embedder-5')\n",
    "# ].sort_values(by='corrs_tune_pc_mean', ascending=False).iloc[0]\n",
    "qa = r.iloc[0]\n",
    "eng1000 = r[(r.feature_space == 'eng1000')].sort_values(\n",
    "    by='corrs_tune_pc_mean', ascending=False).iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(qa['corrs_test'], eng1000['corrs_test'], '.', ms=1)\n",
    "plt.xlabel(f'QA Embedder (mean: {qa[\"corrs_test\"].mean():0.3f})')\n",
    "plt.ylabel(f'Eng1000 (mean: {eng1000[\"corrs_test\"].mean():0.3f})')\n",
    "plt.title('Test Correlations')\n",
    "m_max = max(qa['corrs_test'].max(), eng1000['corrs_test'].max())\n",
    "m_min = min(qa['corrs_test'].min(), eng1000['corrs_test'].min())\n",
    "plt.plot([m_min, m_max], [m_min, m_max], 'k--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check parameters for rerunning expts (alphas, delays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = r[(r.pc_components == -1) * (r.ndelays == 8)].iloc[0]\n",
    "args = r.sort_values(by='corrs_test_mean').iloc[-1]\n",
    "model_params_to_save = joblib.load(\n",
    "    join(args.save_dir_unique, 'model_params.pkl'))\n",
    "print(args.feature_space, args.pc_components, args.ndelays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print which alphas are being used\n",
    "pd.Series(model_params_to_save['alphas_best']).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hybrid models (use pc_components == 1 when it predicts better)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = r[(r.pc_components == -1) * (r.feature_space == 'qa_embedder-5')\n",
    "         ].sort_values(by='corrs_tune_mean', ascending=False).iloc[0]\n",
    "args2 = r[(r.pc_components > 0) * (r.feature_space == 'qa_embedder-5')\n",
    "          ].sort_values(by='corrs_tune_mean', ascending=False).iloc[0]\n",
    "# args = r[]\n",
    "\n",
    "# args2 = r[(r.feature_space == 'eng1000')].iloc[0]\n",
    "# args = r[(r.pc_components == -1) * (r.feature_space == 8)].iloc[0]\n",
    "# args = r[(r.pc_components == -1) * (r.ndelays == 8)].iloc[0]\n",
    "# model_params_to_save = joblib.load(\n",
    "# join(args.save_dir_unique, 'model_params.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentile_thresholds = np.arange(0, 100, 1)\n",
    "corrs_tune_individual = args['corrs_tune']\n",
    "corrs_test_individual = args['corrs_test']\n",
    "corrs_test_pca = args2['corrs_test']\n",
    "res = []\n",
    "for percentile_threshold in percentile_thresholds:\n",
    "    args_top_thresh = np.where(corrs_tune_individual > np.percentile(\n",
    "        corrs_tune_individual, percentile_threshold))[0]\n",
    "    args_non_top_thresh = np.where(corrs_tune_individual <= np.percentile(\n",
    "        corrs_tune_individual, percentile_threshold))[0]\n",
    "    args_total = np.concatenate([args_top_thresh, args_non_top_thresh])\n",
    "    mean_corr_weighted = (corrs_test_individual[args_top_thresh].mean() * args_top_thresh.size +\n",
    "                          corrs_test_pca[args_non_top_thresh].mean() * args_non_top_thresh.size) / args_total.size\n",
    "    # print('mean corr weighted',\n",
    "    #       (corrs_test_individual[args_top_thresh].mean() * args_top_thresh.size +\n",
    "    #        corrs_test_pca[args_non_top_thresh].mean() * args_non_top_thresh.size) / args_total.size\n",
    "    #       )\n",
    "    res.append(mean_corr_weighted)\n",
    "plt.plot(percentile_thresholds, res)\n",
    "plt.axhline(corrs_test_individual.mean(), color='k', linestyle='--')\n",
    "plt.axhline(corrs_test_pca.mean(), color='r', linestyle='--')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.embgam')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "559535f78d940c882783b39501b2581b5193373045707e5f8a51d046029cfd38"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
