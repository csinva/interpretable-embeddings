{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import seaborn as sns\n",
    "import os\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "from matplotlib import pyplot as plt\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "import imodelsx.process_results\n",
    "import qa_questions\n",
    "import random\n",
    "import feature_spaces\n",
    "import encoding_utils\n",
    "import joblib\n",
    "from qa_embedder import QuestionEmbedder\n",
    "from tqdm import tqdm\n",
    "import feature_spaces\n",
    "import dvu\n",
    "dvu.set_style()\n",
    "fit_encoding = __import__('01_fit_encoding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A:\n",
    "    use_test_setup = False\n",
    "    subject = 'UTS03'\n",
    "    # feature_space = 'eng1000'\n",
    "    feature_space = 'qa_embedder-10'\n",
    "    # feature_space = 'qa_embedder-5'\n",
    "    qa_questions_version = 'v1'\n",
    "    num_ngrams_context = 10\n",
    "\n",
    "    # feature_space = 'qa_embedder-25'\n",
    "    # qa_questions_version = 'v1-ending'\n",
    "    qa_embedding_model = 'meta-llama/Meta-Llama-3-8B-Instruct'\n",
    "    # qa_embedding_model = 'mistralai/Mistral-7B-Instruct-v0.2'\n",
    "    # qa_embedding_model = 'mistralai/Mixtral-8x7B-Instruct-v0.1'\n",
    "    trim = 5\n",
    "    num_stories = -1\n",
    "    seed_stories = 1\n",
    "\n",
    "\n",
    "args = A()\n",
    "story_names_train, story_names_test = fit_encoding.get_story_names(args)\n",
    "story_name = story_names_test[:1]\n",
    "s = story_name[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allstories, vectors, wordseqs = feature_spaces.get_features(\n",
    "    args.feature_space,\n",
    "    allstories=story_name,\n",
    "    qa_embedding_model=args.qa_embedding_model,\n",
    "    qa_questions_version=args.qa_questions_version,\n",
    "    downsample=False,\n",
    ")\n",
    "question_answers = vectors[s]\n",
    "ds = wordseqs[s]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize downsampled feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_downsampled = feature_spaces.downsample_word_vectors(\n",
    "    allstories,\n",
    "    vectors,\n",
    "    wordseqs,\n",
    "    strategy='exp',\n",
    ")[s]\n",
    "\n",
    "\n",
    "# # nromalize each row of features_downsampled\n",
    "features_downsampled = features_downsampled / \\\n",
    "    np.linalg.norm(features_downsampled, axis=1)[:, np.newaxis]\n",
    "\n",
    "# # normalize each column of vectors\n",
    "vectors = vectors / np.linalg.norm(vectors, axis=0)[np.newaxis, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for question_num in range(3):\n",
    "    question_anwer_vals = question_answers[:, question_num]\n",
    "    question_answers_downsampled = features_downsampled[:, question_num]\n",
    "\n",
    "    plt.figure(figsize=(13, 4))\n",
    "\n",
    "    # draw vertical line from 0 to each val\n",
    "    trs = ds.tr_times\n",
    "\n",
    "    # xlim = (0, int(max(wordseqs.data_times) - 1))\n",
    "    xlim = (0, 50)\n",
    "    for i in range(len(question_anwer_vals)):\n",
    "        t = ds.data_times[i]\n",
    "        if t >= xlim[0] and t <= xlim[1]:\n",
    "            plt.plot([t, t],\n",
    "                     [0, question_anwer_vals[i]], '-', alpha=0.5, color='gray')\n",
    "            plt.plot(t, question_anwer_vals[i], 'o', color='gray')\n",
    "    idxs = (trs >= xlim[0]) & (trs <= xlim[1])\n",
    "    plt.plot(trs[idxs],\n",
    "             question_answers_downsampled[idxs], '-o', color='C0')\n",
    "\n",
    "    plt.xticks(trs)\n",
    "    plt.xlim(xlim)\n",
    "\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(' '.join([' '.join(ds.chunks()[idx])\n",
    "      for idx in np.arange(len(idxs))[idxs]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize feat examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams_list = feature_spaces._get_ngrams_list_from_words_list(\n",
    "    ds.data, ngram_size=args.num_ngrams_context)\n",
    "questions = qa_questions.get_questions(args.qa_questions_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = QuestionEmbedder(\n",
    "    checkpoint=args.qa_embedding_model, questions=questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = \"<s>[INST]'Input text: watermelon\\nQuestion: Does the input contain a measurement? Answer yes or no.[/INST]\"\n",
    "# qa.llm(prompt, use_cache=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams = np.array(ngrams_list)\n",
    "ngrams = ['thirteen cigarretes', 'how could i make it home i was sobbing'] + \\\n",
    "    ngrams[np.arange(5, 30, 5)].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs = qa(ngrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs_df = pd.DataFrame(embs, columns=questions,\n",
    "                       index=ngrams)\n",
    "embs_df.style.background_gradient(cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.embgam')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "559535f78d940c882783b39501b2581b5193373045707e5f8a51d046029cfd38"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
