{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import feature_spaces\n",
    "import encoding_utils\n",
    "import dvu\n",
    "from transformers import pipeline\n",
    "from transformers.pipelines.pt_utils import KeyDataset\n",
    "import seaborn as sns\n",
    "import os\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import RidgeCV, LogisticRegressionCV\n",
    "\n",
    "from typing import List\n",
    "from matplotlib import pyplot as plt\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "import datasets\n",
    "import encoding_utils, feature_spaces, imodelsx\n",
    "from spacy.lang.en import English\n",
    "import sklearn.preprocessing\n",
    "import pickle as pkl\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from feature_spaces import *\n",
    "from feature_spaces import em_data_dir, data_dir, results_dir\n",
    "# from fit_linear_models import get_dsets\n",
    "# from ridge_utils.SemanticModel import SemanticModel\n",
    "dvu.set_style()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load story texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at narrative stories\n",
    "train_stories, test_stories, allstories = encoding_utils.get_allstories([1, 2, 3, 4, 5])\n",
    "wordseqs = feature_spaces.get_story_wordseqs(train_stories)\n",
    "texts = [' '.join(wordseqs[k].data) for k in wordseqs.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('narrative_stories.txt', 'w') as f:\n",
    "    f.write('\\n'.join(texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save prepocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit an fMRI preprocessor\n",
    "narrative_stories = texts\n",
    "# print(len(narrative_stories)) # 26 stories\n",
    "ngrams_lists = [\n",
    "    imodelsx.util.generate_ngrams_list(story, ngrams=8,\n",
    "                                    all_ngrams=False, tokenizer_ngrams=English().tokenizer)\n",
    "    for story in narrative_stories\n",
    "]\n",
    "\n",
    "# merge all the lists in ngrams_lists\n",
    "ngrams_list = sum(ngrams_lists, [])\n",
    "embs = imodelsx.util.get_embs_llm(ngrams_list, 'bert-base-uncased')\n",
    "preproc = sklearn.preprocessing.StandardScaler().fit(embs)\n",
    "pkl.dump(open('preproc.pkl', 'wb'), preproc)\n",
    "print(len(ngrams_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save mini-weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_mini_weights(num_top=1000,\n",
    "    save_dir='~/mntv1/deep-fMRI/results/encoding/bert-10__ndel=4/UTS03'):\n",
    "    \"\"\"Call this once to save only the weights for the top voxels\n",
    "    (All voxels is too big)\n",
    "    Requires the full file weights.npz\n",
    "    \"\"\"\n",
    "    # load weights\n",
    "    weights_npz = np.load(join(save_dir, 'weights.npz'))\n",
    "    weights = weights_npz['arr_0']\n",
    "    weights = weights.reshape(4, -1, 768)\n",
    "    # mean over delays dimension...\n",
    "    weights = weights.mean(axis=0).squeeze()\n",
    "    weights = weights.T  # make it (768, n_outputs)\n",
    "\n",
    "    # load corrs\n",
    "    corrs_val = np.load(join(save_dir, 'corrs.npz'))['arr_0']\n",
    "    top_idxs = np.argsort(corrs_val)[::-1]\n",
    "\n",
    "    # save top weights only\n",
    "    weights = weights[:, top_idxs[:num_top]]\n",
    "    pkl.dump(weights, open(join(save_dir, 'weights.pkl'), 'wb'))\n",
    "save_mini_weights()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.embgam')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "559535f78d940c882783b39501b2581b5193373045707e5f8a51d046029cfd38"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
