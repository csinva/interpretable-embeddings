{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3122c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import sklearn.metrics\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# folder = \"/Users/johnmorris/Projects/interpretable-embeddings/scripts/d3/out\"\n",
    "folder = 'out'\n",
    "# folder = 'out__one_shot'\n",
    "paths = glob.glob(os.path.join(folder, \"d3_*.csv\"))\n",
    "\n",
    "paths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75f710a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(path):\n",
    "    lines = open(path).readlines()\n",
    "    lines = lines[7:]  # discard header\n",
    "    all_data = []\n",
    "    for line in lines:\n",
    "        idx, data_str = eval(line)\n",
    "        all_data.append(eval(data_str))\n",
    "    return pd.DataFrame(all_data, columns=['task', 'idx', 'true_label', 'pred_label', 'answer', 'model'])\n",
    "\n",
    "\n",
    "dfs = [read_csv(path) for path in paths]\n",
    "df = pd.concat(dfs)\n",
    "\n",
    "# add example_len\n",
    "df['example_len'] = None\n",
    "for task in df.task.unique():\n",
    "    task_str = '_'.join(task.split('_')[:-1])\n",
    "    examples = pd.read_csv(f'd3_processed/{task_str}.csv')\n",
    "    examples['example_len'] = examples['input'].apply(lambda x: len(x.split()))\n",
    "    # set example_len for each task based on \"idx\" column\n",
    "    df.loc[df.task == task, 'example_len'] = df[df.task ==\n",
    "                                                task].idx.apply(lambda x: examples.loc[x].example_len)\n",
    "\n",
    "# add ensemble model\n",
    "df['majority_vote'] = df.groupby(['task', 'idx'])['pred_label'].transform(\n",
    "    lambda x: x.value_counts().idxmax())\n",
    "d_ens = df[df.model == 'meta']\n",
    "d_ens['model'] = 'ensemble'\n",
    "d_ens['pred_label'] = d_ens['majority_vote']\n",
    "df = pd.concat([df, d_ens])\n",
    "\n",
    "df['correct'] = df['true_label'] == df['pred_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a01fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['example_len'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0373b50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['example_len'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1019ee93",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('model')['correct'].mean()\n",
    "# df[df.example_len <= 100000].groupby('model')['correct'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31b9003",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context('talk')\n",
    "d_plot = df\n",
    "# d_plot = df[df.example_len <= 1000]\n",
    "d_plot = d_plot[~d_plot.model.isin(['ensemble'])]\n",
    "d_plot = d_plot.groupby(['model', 'task'])['correct'].mean().reset_index()\n",
    "d_plot['correct'] = d_plot['correct'].apply(lambda x: max(x, 1 - x))\n",
    "d_plot['model'] = d_plot['model'].apply(lambda x:\n",
    "                                        {'meta': 'LLaMA-3 (8B)', 'ensemble': 'Ensemble', 'mistral': 'Mistral (7B)', 'openai': 'GPT-3.5', 'gpt4': 'GPT-4'}.get(x, x))\n",
    "# display(d_plot)\n",
    "\n",
    "display(d_plot.groupby('model')['correct'].mean())\n",
    "# plot boxplot where each point is a task\n",
    "plt.figure(figsize=(10, 5))\n",
    "barplot = sns.barplot(x='model', y='correct', data=d_plot,\n",
    "                      order=['LLaMA-3 (8B)', 'Mistral (7B)',\n",
    "                             'GPT-3.5', 'GPT-4'],\n",
    "                      estimator='mean', errorbar=('ci', 95), err_kws={'color': 'black'}, capsize=0.1, alpha=0.3)\n",
    "\n",
    "# Annotate the bars with the mean values\n",
    "for p in barplot.patches:\n",
    "    height = p.get_height()\n",
    "    barplot.annotate(f'{height:.3f}',\n",
    "                     xy=(p.get_x() + p.get_width() / 2., height),\n",
    "                     xytext=(33, 6),  # 9 points vertical offset\n",
    "                     fontsize='x-small',\n",
    "                     textcoords='offset points',\n",
    "                     color='#72a6c2',\n",
    "                     ha='center', va='center')\n",
    "\n",
    "# show points\n",
    "sns.stripplot(x='model', y='correct', data=d_plot, color='gray', alpha=0.5)\n",
    "sns.despine()\n",
    "plt.xlabel('Question-answering LLM')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.savefig('d3_accuracy.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec008c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['model'])['correct'].sem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86265dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in df['model'].unique():\n",
    "    model_df = df[df['model'] == model]\n",
    "    print(model, sklearn.metrics.f1_score(\n",
    "        model_df['true_label'], model_df['pred_label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac807c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .reset_index().pivot(index='task', columns='model', values='correct').to_latex()\n",
    "d = df.groupby(['model', 'task'])['correct'].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b532f684",
   "metadata": {},
   "outputs": [],
   "source": [
    "d['correct'] = d['correct'].apply(lambda x: max(x, 1 - x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c403a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "d.groupby('model')['correct'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f3a336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fullly display d\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    display(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8600038",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
